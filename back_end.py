import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import streamlit as st
import pickle
from fpdf import FPDF
import base64


# æ•°æ®åŠ è½½ä¸æ¢ç´¢æ€§æ•°æ®åˆ†æ (EDA) æ¨¡å—
def load_and_explore_data(file_path):
    try:
        data = pd.read_csv(file_path)
    except FileNotFoundError:
        st.error(f"æ•°æ®é›†æ–‡ä»¶ '{file_path}' æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶åå’Œè·¯å¾„ã€‚")
        return None

    # æ‰‹åŠ¨å®šä¹‰æ˜ å°„å…³ç³»
    gender_mapping = {'F': 0, 'M': 1}
    class_mapping = {'N': 0, 'P': 1, 'Y': 2}

    # å¯¹Genderå’ŒClassåˆ—è¿›è¡Œç¼–ç 
    data['Gender'] = data['Gender'].str.strip().map(gender_mapping)
    data['CLASS'] = data['CLASS'].str.strip().map(class_mapping)

    # æŸ¥çœ‹æ•°æ®çš„åŸºæœ¬ä¿¡æ¯
    #st.write("\nData Description:")
    #st.write(data.describe())

    # æ£€æŸ¥ç¼ºå¤±å€¼
    #st.write("\nMissing Values:")
    #st.write(data.isnull().sum())

    # æ•°æ®åˆ†å¸ƒå¯è§†åŒ–
    '''
    num_columns = len(data.columns[:-1])
    num_rows = math.ceil(num_columns / 3)
    plt.figure(figsize=(12, 4 * num_rows))
    for i, column in enumerate(data.columns[:-1], 1):
        plt.subplot(num_rows, 3, i)
        sns.histplot(data[column], kde=True, bins=30)
        plt.title(f'Distribution of {column}')
    plt.tight_layout()
    st.pyplot()

    # ç›¸å…³æ€§çŸ©é˜µ
    plt.figure(figsize=(10, 8))
    sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')
    plt.title('Correlation Matrix')
    st.pyplot()
    '''

    return data


# æ•°æ®é¢„å¤„ç†æ¨¡å—
def preprocess_data(data):
    if data is None:
        return None, None

    # ç‰¹å¾ä¸æ ‡ç­¾åˆ†ç¦»ï¼Œå‡è®¾CLASSæ˜¯ç›®æ ‡å˜é‡
    X = data.drop(columns=['CLASS']).drop(columns=['ID']).drop(columns=['No_Pation'])
    y = data['CLASS']

    # æ•°æ®æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # ä¿å­˜é¢„å¤„ç†å¯¹è±¡
    with open('preprocessor.pkl', 'wb') as f:
        pickle.dump(scaler, f)

    # æ•°æ®é›†åˆ’åˆ†
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

    return X_train, X_test, y_train, y_test


# æ¨¡å‹å¼€å‘ä¸è¯„ä¼°æ¨¡å—
def train_and_evaluate_models(X_train, X_test, y_train, y_test):
    if X_train is None or X_test is None or y_train is None or y_test is None:
        return None, None

    # å®šä¹‰æ¨¡å‹
    models = {
        "Logistic Regression": LogisticRegression(),
        "Random Forest": RandomForestClassifier(random_state=42),
        "Gradient Boosting": GradientBoostingClassifier(random_state=42)
    }

    # è®­ç»ƒä¸è¯„ä¼°
    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)
        results[name] = {
            "Accuracy": accuracy_score(y_test, y_pred),
            "Precision": precision_score(y_test, y_pred, average='macro'),
            "Recall": recall_score(y_test, y_pred, average='macro'),
            "F1-Score": f1_score(y_test, y_pred, average='macro'),
            "AUC-ROC": roc_auc_score(y_test, y_pred_proba, multi_class='ovr')
        }

    # ç»“æœå±•ç¤º
    results_df = pd.DataFrame(results).T
    #st.write("\nModel Evaluation Results:")
    #st.write(results_df)

    return results_df


# é›†æˆå­¦ä¹ æ¨¡å—
def create_and_evaluate_voting_clf(X_train, X_test, y_train, y_test):
    if X_train is None or X_test is None or y_train is None or y_test is None:
        return None

    # åˆ›å»ºé›†æˆæ¨¡å‹
    voting_clf = VotingClassifier(estimators=[
        ('lr', LogisticRegression()),
        ('rf', RandomForestClassifier(random_state=42)),
        ('gb', GradientBoostingClassifier(random_state=42))
    ], voting='soft')

    # è®­ç»ƒä¸è¯„ä¼°
    voting_clf.fit(X_train, y_train)
    y_pred_voting = voting_clf.predict(X_test)
    y_pred_voting_proba = voting_clf.predict_proba(X_test)

    voting_results = {
        "Accuracy": accuracy_score(y_test, y_pred_voting),
        "Precision": precision_score(y_test, y_pred_voting, average='macro'),
        "Recall": recall_score(y_test, y_pred_voting, average='macro'),
        "F1-Score": f1_score(y_test, y_pred_voting, average='macro'),
        "AUC-ROC": roc_auc_score(y_test, y_pred_voting_proba, multi_class='ovr')
    }

    #st.write("\nVoting Classifier Results:", voting_results)

    # ä¿å­˜æ¨¡å‹
    try:
        with open('voting_clf.pkl', 'wb') as f:
            pickle.dump(voting_clf, f)
    except Exception as e:
        st.error(f"ä¿å­˜æ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    return voting_results


# ç”¨æˆ·ç•Œé¢æ¨¡å—
def create_user_interface():
    # åŠ è½½æ¨¡å‹
    try:
        with open('voting_clf.pkl', 'rb') as f:
            model = pickle.load(f)
        with open('preprocessor.pkl', 'rb') as f:
            preprocessor = pickle.load(f)
    except FileNotFoundError:
        st.error("æ¨¡å‹æ–‡ä»¶æˆ–é¢„å¤„ç†å¯¹è±¡æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹ã€‚")
        return

    # æ‰‹åŠ¨å®šä¹‰æ˜ å°„å…³ç³»
    gender_mapping = {'F': 0, 'M': 1}

    st.title("Diabetes Early Detection Tool ğŸ©º")
    st.markdown("""
    This tool is designed to assist healthcare professionals in predicting the likelihood of diabetes based on patient data.
    """)

    # ç”¨æˆ·è¾“å…¥éƒ¨åˆ†
    st.sidebar.header("Patient Data Input")
    gender = st.sidebar.selectbox("Genderï¼ˆæ€§åˆ«ï¼‰", ['F', 'M'])
    age = st.sidebar.number_input("Ageï¼ˆå¹´é¾„ï¼‰", min_value=0, max_value=100, value=30)
    urea = st.sidebar.number_input("Ureaï¼ˆå°¿ç´ ï¼Œmmol/Lï¼‰", min_value=0.0, max_value=100.0, value=5.0)
    cr = st.sidebar.number_input("Crï¼ˆè‚Œé…ï¼ŒÎ¼mol/Lï¼‰", min_value=0, max_value=1000, value=50)
    hba1c = st.sidebar.number_input("HbA1cï¼ˆç³–åŒ–è¡€çº¢è›‹ç™½ï¼Œ%ï¼‰", min_value=0.0, max_value=20.0, value=5.0)
    chol = st.sidebar.number_input("Cholï¼ˆæ€»èƒ†å›ºé†‡ï¼Œmmol/Lï¼‰", min_value=0.0, max_value=10.0, value=5.0)
    tg = st.sidebar.number_input("TGï¼ˆç”˜æ²¹ä¸‰é…¯ï¼Œmmol/Lï¼‰", min_value=0.0, max_value=10.0, value=1.0)
    hdl = st.sidebar.number_input("HDLï¼ˆé«˜å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡ï¼Œmmol/Lï¼‰", min_value=0.0, max_value=5.0, value=1.0)
    ldl = st.sidebar.number_input("LDLï¼ˆä½å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡ï¼Œmmol/Lï¼‰", min_value=0.0, max_value=10.0, value=2.0)
    vldl = st.sidebar.number_input("VLDLï¼ˆæä½å¯†åº¦è„‚è›‹ç™½èƒ†å›ºé†‡ï¼Œmmol/Lï¼‰", min_value=0.0, max_value=10.0, value=1.0)
    bmi = st.sidebar.number_input("BMIï¼ˆèº«ä½“è´¨é‡æŒ‡æ•°ï¼Œkg/mÂ²ï¼‰", min_value=0.0, max_value=60.0, value=25.0)

    # é¢„æµ‹æŒ‰é’®
    if st.sidebar.button("Predict"):
        gender_encoded = gender_mapping[gender]
        input_data = np.array([[gender_encoded, age, urea, cr, hba1c, chol, tg, hdl, ldl, vldl, bmi]])
        try:
            # ä½¿ç”¨ä¿å­˜çš„é¢„å¤„ç†å¯¹è±¡è¿›è¡Œè½¬æ¢
            input_data = preprocessor.transform(input_data)
            prediction = model.predict(input_data)[0]
            probability = model.predict_proba(input_data)[0][1]
        except Exception as e:
            st.error(f"é¢„æµ‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return

        # å®æ—¶åé¦ˆç»“æœ
        if prediction == 1:
            st.error(f"The patient is at risk of diabetes (Probability: {probability:.2f}).")
        else:
            st.success(f"The patient is not at risk of diabetes (Probability: {probability:.2f}).")

        # å¯è§†åŒ–ç»“æœ
        st.subheader("Prediction Probability")
        fig, ax = plt.subplots()
        ax.bar(["No Diabetes", "Diabetes"], [1 - probability, probability], color=["green", "red"])
        ax.set_ylim(0, 1)
        ax.set_ylabel("Probability")
        st.pyplot(fig)

        # æ•°æ®åˆ†æå¯è§†åŒ–
        st.subheader("Data Distribution Analysis")
        data = pd.DataFrame({
            "Feature": ["Gender", "Age", "Urea", "Cr", "HbA1c", "Chol", "TG", "HDL", "LDL", "VLDL", "BMI"],
            "Value": [gender, age, urea, cr, hba1c, chol, tg, hdl, ldl, vldl, bmi]
        })
        data["Feature"] = data["Feature"].astype(str)

        fig, ax = plt.subplots()
        sns.barplot(data=data, x="Feature", y="Value", ax=ax)
        plt.xticks(rotation=45)
        st.pyplot(fig)

    # å¯å®šåˆ¶æ€§ï¼šå¯¼å‡ºåŠŸèƒ½
    def create_download_link(val, filename):
        b64 = base64.b64encode(val).decode()
        return f'<a href="data:application/octet-stream;base64,{b64}" download="{filename}">Download {filename}</a>'

    if st.sidebar.button("Export Results as PDF"):
        if 'prediction' not in locals() or 'probability' not in locals():
            st.error("è¯·å…ˆè¿›è¡Œé¢„æµ‹ï¼Œå†å¯¼å‡ºç»“æœã€‚")
            return
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial", size=12)
        pdf.cell(200, 10, txt="Diabetes Prediction Report", ln=True, align="C")
        pdf.cell(200, 10, txt=f"Prediction: {'At Risk' if prediction == 1 else 'Not At Risk'}", ln=True)
        pdf.cell(200, 10, txt=f"Probability: {probability:.2f}", ln=True)

        pdf_output = pdf.output(dest="S").encode("latin-1")
        html = create_download_link(pdf_output, "prediction_report.pdf")
        st.markdown(html, unsafe_allow_html=True)

    # æ”¯æŒä¸åé¦ˆ
    st.sidebar.header("Support & Feedback")
    st.sidebar.markdown("""
        For help, please refer to the [User Guide](#) or contact support@example.com.
        """)
    feedback = st.sidebar.text_area("Your Feedback")
    if st.sidebar.button("Submit Feedback"):
        try:
            with open("feedback.txt", "a") as f:
                f.write(feedback + "\n")
            st.sidebar.success("Thank you for your feedback!")
        except Exception as e:
            st.sidebar.error(f"æäº¤åé¦ˆæ—¶å‘ç”Ÿé”™è¯¯: {e}")
